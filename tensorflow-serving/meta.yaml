{% set version = "2.6.0" %}

package:
   name: tensorflow-serving
   version: {{ version }}

source:
   git_url: https://github.com/tensorflow/serving.git
   git_rev: {{ version }}
   patches:
     - 0000a-TF-Build-fix-x86-64.patch       # [x86_64 and (build_type == 'cpu' or (build_type == 'cuda' and cudatoolkit == '10.2' and py == 38))]
     - 0000b-Fix-plus-memcpy-patch.patch     # [x86_64 and build_type == 'cuda' and ((cudatoolkit == '10.2' and py<38) or (cudatoolkit == '11.0' or cudatoolkit == '11.2'))]
     - 0001-TF-Build-fix-ppc64le.patch       # [ppc64le]
 
build:
  number: 1
  string: h{{ PKG_HASH }}_{{ build_type }}_py{{ python | replace(".", "") }}_pb{{ protobuf | replace(".*", "")}}_{{ PKG_BUILDNUM }} # [build_type == 'cpu'] 
  string: h{{ PKG_HASH }}_{{ build_type }}{{ cudatoolkit | replace(".*", "") }}_py{{ python | replace(".", "") }}_pb{{ protobuf | replace(".*", "")}}_{{ PKG_BUILDNUM }} # [build_type == 'cuda']
{% if build_type == 'cuda' %}
  script_env:
    - CUDA_HOME
{% endif %}

requirements:
  build:
   - {{ compiler('c') }}
   - {{ compiler('cxx') }}
   - automake
   - libtool
   - make
   - git >={{ git }}
   - patch
  host:
   - libevent {{ libevent }}
   - bazel {{ bazel }}
   - cudnn {{ cudnn }}                 # [build_type == 'cuda']
   - nccl {{ nccl }}                   # [build_type == 'cuda']
   # Temporarily disable TensorRT
   #   - tensorrt {{ tensorrt }}           # [build_type == 'cuda' and py<38]
   - libmemcpy_wrapper                 # [x86_64 and build_type == 'cuda' and (cudatoolkit=='11.0' or cudatoolkit=='11.2' or (cudatoolkit == '10.2' and py<38))]
   - numpy {{ numpy }}
   - grpcio {{ grpcio }}
   - python {{ python }}
  run:
   - libevent {{ libevent }}
   - grpcio {{ grpcio }}
   - protobuf 3.9                    # currently tf-serving only works with pb 3.9
   - cudatoolkit {{ cudatoolkit }}   # [build_type == 'cuda']
   - cudnn {{ cudnn }}               # [build_type == 'cuda']
   - nccl {{ nccl }}                 # [build_type == 'cuda']
   # Temporarily disable TensorRT 
   #- tensorrt {{ tensorrt }}         # [build_type == 'cuda' and py<38]
   - libmemcpy_wrapper               # [x86_64 and build_type == 'cuda' and (cudatoolkit=='11.0' or cudatoolkit=='11.2' or (cudatoolkit == '10.2' and py<38))]

about:
  home: https://www.tensorflow.org/tfx/guide/serving
  license: Apache 2.0
  license_family: Apache
  license_file: LICENSE
  summary: TensorFlow Serving is an open-source library for serving machine learning models
  description: |
    TensorFlow Serving is a flexible, high-performance serving system for machine learning models,
    designed for production environments. TensorFlow Serving makes it easy to deploy new algorithms
    and experiments, while keeping the same server architecture and APIs. TensorFlow Serving provides
    out-of-the-box integration with TensorFlow models, but can be easily extended to serve other
    types of models and data.
  dev_url: https://github.com/tensorflow/serving/
  doc_url: https://www.tensorflow.org/tfx/guide/serving
  doc_source_url: https://github.com/tensorflow/serving/tree/master/tensorflow_serving/g3doc

extra:
  recipe-maintainers:
    - open-ce/open-ce-dev-team
