{% set version = "2.4.1" %}

package:
   name: tensorflow-serving
   version: {{ version }}

source:
   git_url: https://github.com/tensorflow/serving.git
   git_rev: {{ version }}
   patches:
     - 0000a-TF-Build-fix-x86-64.patch       # [x86_64 and (build_type == 'cpu' or (build_type == 'cuda' and cudatoolkit == '10.2' and py == 38))]
     - 0000b-Fix-plus-memcpy-patch.patch     # [x86_64 and build_type == 'cuda' and ((cudatoolkit == '10.2' and py<38) or (cudatoolkit == '11.0'))]
     - 0001-TF-Build-fix-ppc64le.patch       # [ppc64le]
 
build:
  number: 4
  string: h{{ PKG_HASH }}_{{ build_type }}_py{{ python | replace(".", "") }}_pb{{ protobuf | replace(".*", "")}}_{{ PKG_BUILDNUM }} # [build_type == 'cpu'] 
  string: h{{ PKG_HASH }}_{{ build_type }}{{ cudatoolkit | replace(".*", "") }}_py{{ python | replace(".", "") }}_pb{{ protobuf | replace(".*", "")}}_{{ PKG_BUILDNUM }} # [build_type == 'cuda']
{% if build_type == 'cuda' %}
  script_env:
    - CUDA_HOME
{% endif %}
  ignore_run_exports:
    - libgcc-ng
    - libstdcxx-ng

requirements:
  build:
   - {{ compiler('c') }}
   - {{ compiler('cxx') }}
   # Use pins to control cos6/cos7 match
   - libgcc-ng  {{ libgcc }}
   - libstdcxx-ng  {{ libstdcxx }}
   - automake
   - libtool
   - make
   - libgcc                 # [x86_64 and build_type == 'cuda']
   - git >={{ git }}
   - patch
  host:
   - libevent {{ libevent }}
   - bazel {{ bazel }}
   - cudnn {{ cudnn }}                 # [build_type == 'cuda']
   - nccl {{ nccl }}                   # [build_type == 'cuda']
   - tensorrt {{ tensorrt }}           # [build_type == 'cuda' and py<38]
   - libmemcpy_wrapper                 # [x86_64 and build_type == 'cuda' and cudatoolkit=='11.0']
   - numpy {{ numpy }}
   - grpcio {{ grpcio }}
   - python {{ python }}
   # Use pins to control cos6/cos7 match
   - libgcc-ng  {{ libgcc }}
   - libstdcxx-ng  {{ libstdcxx }}
  run:
   - libevent {{ libevent }}
   - grpcio {{ grpcio }}
   - protobuf 3.9                    # currently tf-serving only works with pb 3.9
   - cudatoolkit {{ cudatoolkit }}   # [build_type == 'cuda']
   - cudnn {{ cudnn }}               # [build_type == 'cuda']
   - nccl {{ nccl }}                 # [build_type == 'cuda']
   - tensorrt {{ tensorrt }}         # [build_type == 'cuda' and py<38]
   - libmemcpy_wrapper                 # [x86_64 and build_type == 'cuda' and cudatoolkit=='11.0']
   # Use pins to control cos6/cos7 match
   - libgcc-ng  {{ libgcc }}
   - libstdcxx-ng  {{ libstdcxx }}

about:
  home: https://www.tensorflow.org/tfx/guide/serving
  license: Apache 2.0
  license_family: Apache
  license_file: LICENSE
  summary: TensorFlow Serving is an open-source library for serving machine learning models
  description: |
    TensorFlow Serving is a flexible, high-performance serving system for machine learning models,
    designed for production environments. TensorFlow Serving makes it easy to deploy new algorithms
    and experiments, while keeping the same server architecture and APIs. TensorFlow Serving provides
    out-of-the-box integration with TensorFlow models, but can be easily extended to serve other
    types of models and data.
  dev_url: https://github.com/tensorflow/serving/
  doc_url: https://www.tensorflow.org/tfx/guide/serving
  doc_source_url: https://github.com/tensorflow/serving/tree/master/tensorflow_serving/g3doc

extra:
  recipe-maintainers:
    - open-ce/open-ce-dev-team
